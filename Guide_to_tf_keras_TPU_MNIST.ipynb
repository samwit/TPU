{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guide to tf.keras TPU MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samwit/TPU/blob/master/Guide_to_tf_keras_TPU_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ON-UmcT_ZFqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Guide to tf.keras for TPUs on Colabs\n",
        "\n",
        "Here is a very quick implemention and walkthrough to show using TPUs with Keras in Colabs\n",
        "\n",
        "By Sam Witteveen   \n",
        "twitter: [sam_witteveen](https://twitter.com/sam_witteveen)\n",
        "\n",
        "License: Apache 2.0\n"
      ]
    },
    {
      "metadata": {
        "id": "dPamRBokUZEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95qn1rJyHFz5",
        "colab_type": "code",
        "outputId": "e3db7e3c-a2de-4f59-840e-742e1e7917ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n",
            "2.1.6-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zq4l11_Dtx8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check for TPU\n",
        "\n",
        "To Test if you have GPU set up\n",
        "\n",
        "Run the Cell below\n",
        "\n",
        "if no TPU is found press Runtime (in the menu at the top) and choose \"Change Runtime Type\" to TPU\n",
        "\n",
        "The TPU_ADDRESS variable will be needed to pass into the distribution strategy."
      ]
    },
    {
      "metadata": {
        "id": "dwqHrONrZtng",
        "colab_type": "code",
        "outputId": "5db8689a-bd81-4137-b713-f261315bd049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "    print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.37.125.210:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I6mOaxj3k30j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normal MNIST Stuff"
      ]
    },
    {
      "metadata": {
        "id": "181VT0eOUkL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHmvV1heVGDi",
        "colab_type": "code",
        "outputId": "7b37a3cc-e11f-4e67-ce2a-9d62b33a7309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1tidRmu9VM4E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfinmHzDX6SH",
        "colab_type": "code",
        "outputId": "dcbe0423-1d3b-4682-e15e-65376815a45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HpOYyqEnX-G1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_K39jsGzJL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use tf.data\n",
        "\n",
        "you need to make sure you have drop_remainder = True as TPUs need to have a fixed shape"
      ]
    },
    {
      "metadata": {
        "id": "abbwQQfH0td3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(batch_size=1024):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.cache() # Loads the data into memory since its such a small dataset\n",
        "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() \n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVu91avJzMAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_input_fn(batch_size=1024):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_spUwX0VYGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make the model\n",
        "\n",
        "you must pass in an input shape and batch size as TPUs (and XLA) require fixed shapes \n",
        "\n",
        "The rest of the model is just a simple CNN"
      ]
    },
    {
      "metadata": {
        "id": "qHzyhDMhVXHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Inp = tf.keras.Input(\n",
        "      name='input', shape=input_shape, batch_size=batch_size, dtype=tf.float32)\n",
        "x = Conv2D(32, kernel_size=(3, 3), activation='relu',name = 'Conv_01')(Inp)\n",
        "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_01')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_02')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_02')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_03')(x)\n",
        "x = Flatten(name = 'Flatten_01')(x)\n",
        "x = Dense(64, activation='relu',name = 'Dense_01')(x)\n",
        "x = Dropout(0.5,name = 'Dropout_02')(x)\n",
        "output = Dense(num_classes, activation='softmax',name = 'Dense_02')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj-jMmGnuKX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[Inp], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gR1LcamtbOWg",
        "colab_type": "code",
        "outputId": "9dd7a92c-a26d-4090-e6ce-4315e8b1af8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (1024, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "Conv_01 (Conv2D)             (1024, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool_01 (MaxPooling2D)    (1024, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_02 (Conv2D)             (1024, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "MaxPool_02 (MaxPooling2D)    (1024, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "Conv_03 (Conv2D)             (1024, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "Flatten_01 (Flatten)         (1024, 576)               0         \n",
            "_________________________________________________________________\n",
            "Dense_01 (Dense)             (1024, 64)                36928     \n",
            "_________________________________________________________________\n",
            "Dropout_02 (Dropout)         (1024, 64)                0         \n",
            "_________________________________________________________________\n",
            "Dense_02 (Dense)             (1024, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D00NKseRuOR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use a tf optimizer rather than a Keras one for now\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "model.compile(\n",
        "      optimizer=opt,\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQnZM5JYlRvs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the TPU from a Keras Model\n",
        "\n",
        "tf.contrib.tpu.keras_to_tpu_model will eventually go away and you will pass it into the model.compile as a distribution strategy, but for 1.11 this works. \n",
        "\n",
        "We can see this is a TPUv2 with 8 cores  \n",
        "\n",
        "For batching you want to have a batch of 128 per core so 1024 overall  \n",
        "\n",
        "You could also use 128,256, 512 etc "
      ]
    },
    {
      "metadata": {
        "id": "G-piuNdoWJGS",
        "colab_type": "code",
        "outputId": "24da44f1-6acb-4316-dc53-f045a8c9074d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.37.125.210:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12649683245029871286)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6245310002541433061)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 6599489638133574828)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1235230034565965184)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6965938561129269553)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8950554075877392157)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17527891154227110211)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9783944454974393200)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10317572289095541755)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13202310898679087843)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1728696596045888679)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 10019855982358009038)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2u9PUA9W7NK",
        "colab_type": "code",
        "outputId": "92cc58e1-e10c-495c-ee56-f7393289b708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (1024, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "Conv_01 (Conv2D)             (1024, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool_01 (MaxPooling2D)    (1024, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_02 (Conv2D)             (1024, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "MaxPool_02 (MaxPooling2D)    (1024, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "Conv_03 (Conv2D)             (1024, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "Flatten_01 (Flatten)         (1024, 576)               0         \n",
            "_________________________________________________________________\n",
            "Dense_01 (Dense)             (1024, 64)                36928     \n",
            "_________________________________________________________________\n",
            "Dropout_02 (Dropout)         (1024, 64)                0         \n",
            "_________________________________________________________________\n",
            "Dense_02 (Dense)             (1024, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_w2mss3nltod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training using tf.data pipeline \n",
        "\n",
        "obviously training MNIST on a TPU is a bit overkill and the TPU barely gets a chance to warm up"
      ]
    },
    {
      "metadata": {
        "id": "x20Gu_lxXjOV",
        "colab_type": "code",
        "outputId": "697ea946-a409-4ad6-9a1b-bd635f50f333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(\n",
        "    train_input_fn,\n",
        "    steps_per_epoch = 60,\n",
        "    epochs=10,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(1024,), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 10), dtype=tf.float32, name=None)]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.1533143520355225 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "60/60 [==============================] - 7s 119ms/step - loss: 0.9712 - acc: 0.6931\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 3s 42ms/step - loss: 0.2354 - acc: 0.9318\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.1393 - acc: 0.9603\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 3s 42ms/step - loss: 0.1037 - acc: 0.9706\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.0836 - acc: 0.9765\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.0692 - acc: 0.9804\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 0.0607 - acc: 0.9827\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.0537 - acc: 0.9847\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.0471 - acc: 0.9864\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 3s 44ms/step - loss: 0.0424 - acc: 0.9875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2982a182b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "BbC4yE3zYFhL",
        "colab_type": "code",
        "outputId": "4db7ff61-17ae-46ed-9ff7-1b9a91090f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.save_weights('./MNIST_TPU_1024.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KOMRVG_YYloD",
        "colab_type": "code",
        "outputId": "bedab867-5582-429f-8cc7-2598477049b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.evaluate(test_input_fn,\n",
        "    steps = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(1024,), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 10), dtype=tf.float32, name=None)]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.1337230205535889 secs\n",
            "100/100 [==============================] - 5s 52ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.023827011808753015, 0.99239501953125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "hqMMMhPr4C0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Converting the model back to a CPU model"
      ]
    },
    {
      "metadata": {
        "id": "xxljvuMZNppb",
        "colab_type": "code",
        "outputId": "1e774a47-b6e5-4b15-e5b9-1f1dffc69391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}